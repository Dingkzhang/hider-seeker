{
    "index": 5,
    "month_int": "02",
    "month_name": "February",
    "year_int": "2020",
    "total_days": "29",
    "date_name_start": "Wednesday",
    "date_name_end": "Friday",
    "calendar_info": {
        "29": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 131: Played some league "
                }
            ]
        },
        "28": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 130: Downloaded p-christ algorithms for reinforcement learning"
                },
                {
                    "type": "text",
                    "paragraph": "Goal is to spend the entire month of March getting familiar with PyTorch and the algorithms implmented by p-christ plus A2C and A3C. "
                },
                {
                    "type": "text",
                    "paragraph": "Ran the cartpole problem from his code"
                }
            ]
        },
        "27": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 129: One of the best ways to learn is to look at what other people are doing!"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at PyTorch Neural Network Tutorial"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at PyTorch Classifier tutorial"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at PyTorch Data Parallelism tutorial"
                }
            ]
        },
        "26": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 128: Introduction to PyTorch"
                },
                {
                    "type": "text",
                    "paragraph": "Updated pyTorch to 1.4"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at PyTorch Introduction tutorial"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at PyTorch Autograd tutorial"
                }
            ]
        },
        "25": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 127: Adjusting decision boundary and changing activation function"
                },
                {
                    "type": "text",
                    "paragraph": "Slept at around 10:30 pm last night. Woke up at around 6 am. Body is feeling much better."
                },
                {
                    "type": "text",
                    "paragraph": "Changed the neural network from leaky relu to sigmoid. No changes really. It looks like it is converging very very slightly."
                },
                {
                    "type": "text",
                    "paragraph": "Moving on to the next endeavor. Can't spend another month on this. Sometimes failure is just a part of the process. I will be back :)"
                }
            ]
        },
        "24": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 126: Went to Maht Gaek with an old friend. We talked about AI and life."
                },
                {
                    "type": "text",
                    "paragraph": "Slept for 7.5 hours today. Feeling a lot better than before."
                }
            ]
        },
        "23": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 125: Relaxed today as well >:)"
                }
            ]
        },
        "22": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 124: Used today to relax"
                }
            ]
        },
        "21": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 123: Apologized to a co-worker for being a rude asshole"
                }
            ]
        },
        "20": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 122: Honestly it might be the input data"
                },
                {
                    "type": "text",
                    "paragraph": "Tweaked the weight update a final time."
                },
                {
                    "type": "text",
                    "paragraph": "Tried running with more vision."
                },
                {
                    "type": "text",
                    "paragraph": "The current results are stable. However, they just oscillate in a parabolic path and it shows no sign of converging."
                },
                {
                    "type": "text",
                    "paragraph": "The given input information might not be enough for the machine to tell."
                },
                {
                    "type": "text",
                    "paragraph": "Thinking of adding more input parameters... (Meaning features as inputs for the neural network to detect....)"
                }
            ]
        },
        "19": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 121: Looked up some tips and tweaked some parameters"
                },
                {
                    "type": "text",
                    "paragraph": "Double checked weights for input-hidden layer. Seems all right to me."
                },
                {
                    "type": "text",
                    "paragraph": "Lowered learning rate from 0.0005 to 0.00001. Prevents it from diverging."
                },
                {
                    "type": "text",
                    "paragraph": "Changed min and max reward from range (-5,5) to (-1,1). Seems to result in a smaller error."
                },
                {
                    "type": "text",
                    "paragraph": "The error is not decreasing nor is it increasing. It seems that it is just oscillating between points. I have tried changing the sample size, experience replay size, and target weight update."
                },
                {
                    "type": "text",
                    "paragraph": "It might just be that what I am capturing is not working. Need to reconsider if enough information is there for it to register the pattern. :("
                }
            ]
        },
        "18": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 120: Fixing the weights"
                },
                {
                    "type": "text",
                    "paragraph": "Rechecked the weight update equations. Fixed the hidden -> hidden layer weight update. Still need to do hidden -> input layer weight update fix."
                },
                {
                    "type": "text",
                    "paragraph": "Need to look up and understand common mistakes."
                },
                {
                    "type": "text",
                    "paragraph": "Did re-adjustments on batch_size and experience replay capacity. Seems that bigger batch size led to more stability? (No sure have to look into it)"
                }
            ]
        },
        "17": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 119: Flu A and Flu B woohoo"
                },
                {
                    "type": "text",
                    "paragraph": "Added weight update for input to hidden layer. (Not 100% sure I did it correctly.) Increased number of hidden layer weights."
                },
                {
                    "type": "text",
                    "paragraph": "Results are still diverging. Need to figure out why.... Need to look up commmon DQN mistakes."
                },
                {
                    "type": "text",
                    "paragraph": "Definitely someting wrong with hidden layer and input layer weight updates. Need to look at the math again and figure out what I did wrong."
                }
            ]
        },
        "16": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 118: Practicing in league uwu"
                },
                {
                    "type": "text",
                    "paragraph": "Need to increase the weight size, implement weight update for input to hidden layer, and look up common DQN mistakes."
                }
            ]
        },
        "15": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 117: Back to being sick >:( and just playing some league today"
                }
            ]
        },
        "14": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 116: Valentine's Day"
                },
                {
                    "type": "text",
                    "paragraph": "After adding function limit with relu activation function it seems to not diverge as much. However, after 50k iterations the error starts to increase again."
                },
                {
                    "type": "text",
                    "paragraph": "Changed to leaky relu which actually made the problem worse. Fuck. Still need to implment final layer of weight update..."
                }
            ]
        },
        "13": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 115: Limiting the experience_replay"
                },
                {
                    "type": "text",
                    "paragraph": "Added function to limit experience_replay to 1000 experiences max."
                }
            ]
        },
        "12": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 114: Fixing the divergence issue"
                },
                {
                    "type": "text",
                    "paragraph": "Wasn't really the learning rate that was the problem. I did make it smaller so it takes longer to diverge."
                },
                {
                    "type": "text",
                    "paragraph": "Don't have an experience limit right now. Might also be that the system is picking old data that it never gets rid of old experiences and that it interfering with learning."
                },
                {
                    "type": "text",
                    "paragraph": "Could potentially be the error function. The error is the sum to the power of 2 which will create huge errors. Not good for the system when it suddenly has to increment the weight by a huge amount. Another reason to get rid of old data that can cause variance."
                },
                {
                    "type": "text",
                    "paragraph": "Added weight update for hidden->hidden layer"
                }
            ]
        },
        "11": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 113: Running fun fun"
                },
                {
                    "type": "text",
                    "paragraph": "Think learning rate might be too big. So I set it to 0.001"
                },
                {
                    "type": "text",
                    "paragraph": "Fixed issue where I was only using policy weights and not using target weights for next state."
                },
                {
                    "type": "text",
                    "paragraph": "Ran 5.80 miles in 65:00"
                }
            ]
        },
        "10": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 112: OMG its diverging >:("
                },
                {
                    "type": "text",
                    "paragraph": "Writing back-propagation function. However, the function is diverging! Need to figure out the reason."
                }
            ]
        },
        "09": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 111: Didn't tilt very hard today. Good day :O"
                }
            ]
        },
        "08": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 110: Relaxed today and played league :)"
                }
            ]
        },
        "07": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 109: Working out the math"
                },
                {
                    "type": "text",
                    "paragraph": "Wrote out the back propagation math I need for each weight update."
                }
            ]
        },
        "06": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 108: Intimidated by NN >:()"
                },
                {
                    "type": "text",
                    "paragraph": "Learning how to map back propagation for Deep q Learning"
                }
            ]
        },
        "05": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 107: Working out back propagation equations"
                },
                {
                    "type": "text",
                    "paragraph": "Re-visited some more articles on back propagation."
                },
                {
                    "type": "text",
                    "paragraph": "Look at how other people handled activation functions and output layer"
                },
                {
                    "type": "text",
                    "paragraph": "Re-wrote code to use relu for 1st and 2nd hidden layer. Re-wrote code to use linear output instead of softmax for output layer."
                }
            ]
        },
        "04": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 106: Mistake tilt and in the ZONE (flow state)"
                },
                {
                    "type": "text",
                    "paragraph": "Read Mistake Tile and injustice tilt (Chapter 5) on The Mental Game of Pokwer by Jared Tendler"
                },
                {
                    "type": "text",
                    "paragraph": "Looked at several articles on how to do back-propagation for deep q learning."
                },
                {
                    "type": "text",
                    "paragraph": "Wrote loss and cost function (mean squared error)"
                },
                {
                    "type": "text",
                    "paragraph": "Ran 4.00 miles in 46:09"
                }
            ]
        },
        "03": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 105: Focus Please"
                },
                {
                    "type": "text",
                    "paragraph": "Continued reading chapter 5 on The Mental Game of Pokwer by Jared Tendler"
                },
                {
                    "type": "text",
                    "paragraph": "Read How to Become the Best Programmer in the World by Ohans Emmanuel"
                },
                {
                    "type": "text",
                    "paragraph": "Finished forward propagation and started working on cost function"
                }
            ]
        },
        "02": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 104: League of legends got to d3. :) Also, Must enter flow state for each and everyone of my goals >:("
                }
            ]
        },
        "01": {
            "doesDataExist": true,
            "main_info": [
                {
                    "type": "text",
                    "paragraph": "Day 103: Played a bunch of ranked games. Did not tilt. Good control good practice"
                },
                {
                    "type": "text",
                    "paragraph": "Read the beginning sections of Chapter 5 on The Mental Game of Poker by Jared Tendler"
                },
                {
                    "type": "text",
                    "paragraph": "Corrected forward propagation function. Need to add cost function and backward propagation next"
                }
            ]
        }
    }
}